{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input configuration\n",
    "import os\n",
    "os.chdir('../../configuration')\n",
    "%run config.ipynb\n",
    "\n",
    "# Import all\n",
    "os.chdir(\"../code/methods\")\n",
    "%run 101_imports_updated.ipynb\n",
    "\n",
    "# Set paths\n",
    "os.chdir(\"../setup_paths\")\n",
    "%run 001_setup_path.ipynb\n",
    "\n",
    "# Load local methods\n",
    "os.chdir(\"../methods\")\n",
    "local_methods = os.getcwd()\n",
    "%run 101_imports_updated.ipynb\n",
    "\n",
    "# Load all methods from methods framework\n",
    "# Set path to methods path\n",
    "os.chdir(methods_path)\n",
    "%run 010_methods_all.ipynb\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of Data set : (893, 12)\n",
      " \n",
      " Head of the Dataset: \n",
      " \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0     NaN   \n",
      "1            2         1     NaN   \n",
      "2            3         1     3.0   \n",
      "3            3         1     3.0   \n",
      "4            4         1     1.0   \n",
      "5            4         1     1.0   \n",
      "6            5         0     3.0   \n",
      "7            6         0     3.0   \n",
      "8            7         0     1.0   \n",
      "9            8         0     3.0   \n",
      "\n",
      "                                                Name   Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris   NaN   NaN    NaN   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   NaN   NaN    NaN   \n",
      "2                             Heikkinen, Miss. Laina   NaN  26.0    0.0   \n",
      "3                             Heikkinen, Miss. Laina   NaN  26.0    0.0   \n",
      "4       Futrelle, Mrs. Jacques Heath (Lily May Peel)   NaN  35.0    1.0   \n",
      "5       Futrelle, Mrs. Jacques Heath (Lily May Peel)   NaN  35.0    1.0   \n",
      "6                           Allen, Mr. William Henry   NaN  35.0    0.0   \n",
      "7                                   Moran, Mr. James  male   NaN    0.0   \n",
      "8                            McCarthy, Mr. Timothy J  male  54.0    0.0   \n",
      "9                     Palsson, Master. Gosta Leonard  male   2.0    3.0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0    NaN               NaN      NaN   NaN      NaN  \n",
      "1    NaN               NaN      NaN   NaN      NaN  \n",
      "2    0.0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3    0.0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4    0.0            113803  53.1000  C123        S  \n",
      "5    0.0            113803  53.1000  C123        S  \n",
      "6    0.0            373450   8.0500   NaN        S  \n",
      "7    0.0            330877   8.4583   NaN        Q  \n",
      "8    0.0             17463  51.8625   E46        S  \n",
      "9    1.0            349909  21.0750   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = read_file(df_name,input_path) \n",
    "\n",
    "# #Analyze by describing data\n",
    "log_to_file_algo(algo,output_path_results)\n",
    "print(' Shape of Data set :',df.shape)\n",
    "log_to_file('Shape of Data set : ',output_path_results)\n",
    "log_to_file_result(df.shape,output_path_results)\n",
    "no_of_columns = df.shape[1]\n",
    "\n",
    "# Head of data\n",
    "print(\" \\n Head of the Dataset: \\n \")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tail of the Dataset: \n",
      " \n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "888          887         0     2.0                     Montvila, Rev. Juozas   \n",
      "889          888         1     1.0              Graham, Miss. Margaret Edith   \n",
      "890          889         0     3.0  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "891          890         1     1.0                     Behr, Mr. Karl Howell   \n",
      "892          891         0     3.0                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "888    male  27.0    0.0    0.0      211536  13.00   NaN        S  \n",
      "889  female  19.0    0.0    0.0      112053  30.00   B42        S  \n",
      "890  female   NaN    1.0    2.0  W./C. 6607  23.45   NaN        S  \n",
      "891    male  26.0    0.0    0.0      111369  30.00  C148        C  \n",
      "892    male  32.0    0.0    0.0      370376   7.75   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "# Tail of data\n",
    "print(\" Tail of the Dataset: \\n \")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No.of duplicates removed: 4\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "no_rows_before = df.shape[0]\n",
    "df = duplicate_remove(df)\n",
    "no_rows_after = df.shape[0]\n",
    "print(\" No.of duplicates removed:\",no_rows_before-no_rows_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns deleted: \n",
      "\t Automatically:  ['PassengerId', 'Name']\n",
      "\t Manually:  ['Ticket', 'Cabin']\n"
     ]
    }
   ],
   "source": [
    "# Identify unique values columns for deletion.\n",
    "def unique_value_rows(df):    \n",
    "    rows_count = df.shape[0]\n",
    "    columns_to_drop = []\n",
    "    for col_name in df.columns:    \n",
    "        if(rows_count == len(set(df[col_name]))):\n",
    "            columns_to_drop.append(col_name)\n",
    "    return(columns_to_drop)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "def drop_columns(df,columns_to_drop):    \n",
    "    df =df.drop(columns_to_drop,axis =1)    \n",
    "    log_to_file_result(columns_to_drop,output_path_results)\n",
    "    return df\n",
    "\n",
    "# Automatic deletion of unique value columns\n",
    "columns_to_drop =  unique_value_rows(df)\n",
    "print(\"Columns deleted: \")\n",
    "print(\"\\t Automatically: \", columns_to_drop)\n",
    "# print(df.shape)\n",
    "log_to_file('Columns deleted automatically: ',output_path_results)\n",
    "df = drop_columns(df,columns_to_drop)\n",
    "# print(df.shape)\n",
    "\n",
    "# Manual deletion of unnecessary value columns\n",
    "columns_to_drop = []\n",
    "if( df_name == 'df.csv'): # Note: The below 2 columns hard coded for this specific data frame. This need to be changed for your project.\n",
    "    columns_to_drop = ['Ticket','Cabin']\n",
    "print(\"\\t Manually: \", columns_to_drop)\n",
    "log_to_file('Columns deleted manually: ',output_path_results)\n",
    "df = drop_columns(df,columns_to_drop)\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before convert: \n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 892\n",
      "Data columns (total 8 columns):\n",
      "Survived    889 non-null int64\n",
      "Pclass      887 non-null float64\n",
      "Sex         886 non-null object\n",
      "Age         710 non-null float64\n",
      "SibSp       887 non-null float64\n",
      "Parch       887 non-null float64\n",
      "Fare        887 non-null float64\n",
      "Embarked    885 non-null object\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 62.5+ KB\n",
      "\n",
      " \n",
      " After convert: \n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 892\n",
      "Data columns (total 8 columns):\n",
      "Survived    889 non-null int64\n",
      "Pclass      887 non-null float64\n",
      "Sex         886 non-null object\n",
      "Age         710 non-null float64\n",
      "SibSp       887 non-null float64\n",
      "Parch       887 non-null float64\n",
      "Fare        887 non-null float64\n",
      "Embarked    885 non-null object\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Info of Data\n",
    "print(\"Before convert: \\n \")\n",
    "df.info()\n",
    "\n",
    "def convert_dtype(df,columns_to_convert):\n",
    "    for column_name in columns_to_convert:           \n",
    "        df[column_name] = df[column_name].astype(object)\n",
    "        \n",
    "# Manually convert float type columns to object type. \n",
    "# Like balances and any amounts should be in float only, should not convert.\n",
    "columns_to_convert = []\n",
    "\n",
    "# Uncomment below line and mention your data set columns to convert\n",
    "# columns_to_convert = ['Pclass','Age','SibSp','Parch']\n",
    "convert_dtype(df,columns_to_convert)\n",
    "\n",
    "# Info of Data\n",
    "print(\"\\n \\n After convert: \\n \")\n",
    "df.info()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Numerical columns : \n",
      "  ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      " \n",
      " Categorical columns : \n",
      "  ['Sex', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical columns\n",
    "all_cols,cat_cols,num_cols = separate_numeric_categoric(df)\n",
    "os.chdir(output_path)\n",
    "print(' \\n Numerical columns : \\n ',num_cols)\n",
    "log_to_file('Numerical columns:',output_path_results)\n",
    "log_to_file_result(num_cols,output_path_results)\n",
    "\n",
    "print(' \\n Categorical columns : \\n ',cat_cols)\n",
    "log_to_file('Categorical columns:',output_path_results)\n",
    "log_to_file_result(cat_cols,output_path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Head of data : \n",
      " \n",
      "   Survived  Pclass   Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0         0     NaN   NaN   NaN    NaN    NaN      NaN      NaN\n",
      "1         1     NaN   NaN   NaN    NaN    NaN      NaN      NaN\n",
      "6         0     3.0   NaN  35.0    0.0    0.0   8.0500        S\n",
      "7         0     3.0  male   NaN    0.0    0.0   8.4583        Q\n",
      "8         0     1.0  male  54.0    0.0    0.0  51.8625        S\n",
      "\n",
      " # Before impute: \n",
      "\n",
      "Pclass 2\n",
      "Sex 3\n",
      "Age 179\n",
      "SibSp 2\n",
      "Parch 2\n",
      "Fare 2\n",
      "Embarked 4\n",
      "\n",
      " No.of columns with NA values: 7\n",
      "\n",
      " # After impute: \n",
      "\n",
      "No.of columns with NA values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check missing values before impute\n",
    "print(\" Head of data : \\n \")\n",
    "print(df.head())\n",
    "print('\\n # Before impute: \\n')\n",
    "na_columns_count = check_missing_values(df,all_cols,na_count=0)\n",
    "print('\\n No.of columns with NA values:',na_columns_count)\n",
    "\n",
    "# Impute missing values              \n",
    "df = DataFrameImputer().fit_transform(df)\n",
    "\n",
    "# Check missing values after impute\n",
    "print('\\n # After impute: \\n')\n",
    "na_columns_count = check_missing_values(df,all_cols,na_count=0)\n",
    "print('No.of columns with NA values:',na_columns_count)\n",
    "\n",
    "# # Write final file\n",
    "# write_file(df,local_output_path_csvs,file_name = 'df_missing_values_replaced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:  ['Sex', 'Embarked']\n",
      " \n",
      " All columns after dummy:  ['Survived' 'Pclass' 'Age' 'SibSp' 'Parch' 'Fare' 'Sex_male' 'Embarked_Q'\n",
      " 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "# Create Dummy varibles for categorical varaibles.\n",
    "all_cols,cat_cols,num_cols = separate_numeric_categoric(df)\n",
    "print('Categorical columns: ',cat_cols)\n",
    "df_with_dummy = create_dummy(df,cat_cols)\n",
    "print(' \\n All columns after dummy: ',df_with_dummy.columns.values)\n",
    "\n",
    "# Write final file\n",
    "write_file(df_with_dummy,output_path_csvs,file_name = df_processed_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
